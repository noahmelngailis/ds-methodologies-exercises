{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.impute\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "from acquire import get_titanic_data, get_iris_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Data\n",
    "\n",
    "- Use the function defined in acquire.py to load the iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_iris_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rename the species_name column to just species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'species_name':'species'}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop the species_id and measurement_id columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['species_id', 'measurement_id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = sklearn.model_selection.train_test_split(df, random_state=47, train_size = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode the species name using a sklearn label encoder. Research the inverse_transform method of the label encoder. How might this be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = sklearn.preprocessing.OneHotEncoder()\n",
    "\n",
    "encoder.fit(train[['species']])\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = sklearn.preprocessing.OneHotEncoder()\n",
    "encoder.fit(train[['species']])\n",
    "cols = ['embark_town_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "m = encoder.transform(train[['species']]).todense()\n",
    "train = pd.concat([\n",
    "    train,\n",
    "    pd.DataFrame(m, columns = cols, index=train.index)\n",
    "], axis = 1).drop(columns='species')\n",
    "\n",
    "m = encoder.transform(test[['species']]).todense()\n",
    "test = pd.concat([\n",
    "    test,\n",
    "    pd.DataFrame(m, columns = cols, index=test.index)\n",
    "], axis = 1).drop(columns='species')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a function named prep_iris that accepts the untransformed iris data, and returns the data with the transformations above applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    df.drop(columns = ['species_id', 'measurement_id'], inplace = True)\n",
    "    return df\n",
    "\n",
    "def rename_columns(df):\n",
    "    df.rename(columns = {'species_name':'species'}, inplace = True)\n",
    "    return df\n",
    "\n",
    "def encode_species(train, test):\n",
    "    encoder = sklearn.preprocessing.OneHotEncoder().fit(train[['species']])\n",
    "    cols = ['embark_town_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "    m = encoder.transform(train[['species']]).todense()\n",
    "    train = pd.concat([\n",
    "        train,\n",
    "        pd.DataFrame(m, columns = cols, index=train.index)\n",
    "    ], axis = 1).drop(columns='species')\n",
    "\n",
    "    m = encoder.transform(test[['species']]).todense()\n",
    "    test = pd.concat([\n",
    "        test,\n",
    "        pd.DataFrame(m, columns = cols, index=test.index)\n",
    "    ], axis = 1).drop(columns='species')    \n",
    "    \n",
    "    return encoder, train, test\n",
    "    \n",
    "\n",
    "def prep_iris(df):\n",
    "    df = drop_columns(df)\n",
    "    df = rename_columns(df)\n",
    "    train, test = sklearn.model_selection.train_test_split(df, random_state=123, train_size = .8)\n",
    "    encoder, train, test = encode_species(train, test)\n",
    "    return encoder, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_iris_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, train, test = prep_iris(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Data\n",
    "\n",
    "- *Use the function you defined in acquire.py to load the titanic data set.*\n",
    "- *Handle the missing values in the embark_town and embarked columns.*\n",
    "- *Remove the deck column.*\n",
    "- *Use a label encoder to transform the embarked column.*\n",
    "- Scale the age and fare columns using a min max scaler. Why might this be beneficial? When might you not want to do this?\n",
    "- *Fill the missing values in age. The way you fill these values is up to you. Consider the tradeoffs of different methods.*\n",
    "- Create a function named prep_titanic that accepts the untransformed titanic data, and returns the data with the transformations above applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_titanic_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0945b0a31a2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_titanic_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_titanic_data' is not defined"
     ]
    }
   ],
   "source": [
    "df = get_titanic_data()\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_titanic(df):\n",
    "    df.drop(columns = ['deck', 'embarked', 'class'], inplace = True)\n",
    "    return df\n",
    "df = drop_columns_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = sklearn.model_selection.train_test_split(df, random_state=123, train_size=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57.9792</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "329           329         1       1  female  16.0      0      1  57.9792   \n",
       "\n",
       "    embark_town  alone  \n",
       "329   Cherbourg      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_embark_town(train, test):\n",
    "    train.embark_town = train.embark_town.fillna(\"Southampton\")\n",
    "    test.embark_town = test.embark_town.fillna(\"Southampton\")\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57.9792</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>749</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>421</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63.3583</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "329           329         1       1  female  16.0      0      1  57.9792   \n",
       "749           749         0       3    male  31.0      0      0   7.7500   \n",
       "203           203         0       3    male  45.5      0      0   7.2250   \n",
       "421           421         0       3    male  21.0      0      0   7.7333   \n",
       "97             97         1       1    male  23.0      0      1  63.3583   \n",
       "\n",
       "    embark_town  alone  \n",
       "329   Cherbourg      0  \n",
       "749  Queenstown      1  \n",
       "203   Cherbourg      1  \n",
       "421  Queenstown      1  \n",
       "97    Cherbourg      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = impute_embark_town(train, test)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_embark_town(train, test):\n",
    "    encoder = sklearn.preprocessing.OneHotEncoder().fit(train[['embark_town']])\n",
    "    \n",
    "    cols = ['embark_town_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "    m = encoder.transform(train[['embark_town']]).todense()\n",
    "    train = pd.concat([\n",
    "        train,\n",
    "        pd.DataFrame(m, columns=cols, index=train.index)\n",
    "    ], axis=1).drop(columns='embark_town')\n",
    "    \n",
    "    m = encoder.transform(test[['embark_town']]).todense()\n",
    "    test = pd.concat([\n",
    "        test,\n",
    "        pd.DataFrame(m, columns=cols, index=test.index)\n",
    "    ], axis=1).drop(columns='embark_town')\n",
    "    return encoder, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, train, test = encode_embark_town(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57.9792</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>749</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>421</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63.3583</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "329           329         1       1  female  16.0      0      1  57.9792   \n",
       "749           749         0       3    male  31.0      0      0   7.7500   \n",
       "203           203         0       3    male  45.5      0      0   7.2250   \n",
       "421           421         0       3    male  21.0      0      0   7.7333   \n",
       "97             97         1       1    male  23.0      0      1  63.3583   \n",
       "\n",
       "     alone  embark_town_Cherbourg  embark_town_Queenstown  \\\n",
       "329      0                    1.0                     0.0   \n",
       "749      1                    0.0                     1.0   \n",
       "203      1                    1.0                     0.0   \n",
       "421      1                    0.0                     1.0   \n",
       "97       0                    1.0                     0.0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "329                      0.0  \n",
       "749                      0.0  \n",
       "203                      0.0  \n",
       "421                      0.0  \n",
       "97                       0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_age(train, test):\n",
    "    imputer = sklearn.impute.SimpleImputer(strategy='mean')\n",
    "    imputer.fit(train[['age']])\n",
    "    train.age = imputer.transform(train[['age']])\n",
    "    test.age = imputer.transform(test[['age']])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = impute_age(train, test)\n",
    "train.age.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale_titanic(train, test):\n",
    "\n",
    "#     scaler = sklearn.preprocessing.MinMaxScaler(copy=True).fit(train[['age', 'fare']])\n",
    "\n",
    "#     train_scaled = pd.DataFrame(scaler.transform(train[['age', 'fare']]), columns={'age_scaled', 'fare_scaled'})\n",
    "\n",
    "#     test_scaled = pd.DataFrame(scaler.transform(test[['age', 'fare']]), columns={'age_scaled', 'fare_scaled'})\n",
    "    \n",
    "# #     train = pd.merge([train, train_scaled], )\n",
    "# #     test = pd.merge([test, test_scaled])\n",
    "#     train.merge(train_scaled, how='inner', on='index')\n",
    "#     test.merge(test_scaled, how='inner', on='index')\n",
    "#     return scaler, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_columns(train, test):\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    train[['age','fare']] = scaler.fit_transform(train[['age','fare']])\n",
    "    test[['age','fare']] = scaler.transform(test[['age','fare']])\n",
    "    return scaler, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, train, test = scale_columns(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0.195778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.113168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>749</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.384267</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.566474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>421</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.258608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.283740</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123667</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0.421965</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044893</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>322</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0.371701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.371701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.359135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex       age  sibsp  parch      fare  \\\n",
       "329           329         1       1  female  0.195778      0      1  0.113168   \n",
       "749           749         0       3    male  0.384267      0      0  0.015127   \n",
       "203           203         0       3    male  0.566474      0      0  0.014102   \n",
       "421           421         0       3    male  0.258608      0      0  0.015094   \n",
       "97             97         1       1    male  0.283740      0      1  0.123667   \n",
       "..            ...       ...     ...     ...       ...    ...    ...       ...   \n",
       "98             98         1       2  female  0.421965      0      1  0.044893   \n",
       "322           322         1       2  female  0.371701      0      0  0.024106   \n",
       "382           382         0       3    male  0.396833      0      0  0.015469   \n",
       "365           365         0       3    male  0.371701      0      0  0.014151   \n",
       "510           510         1       3    male  0.359135      0      0  0.015127   \n",
       "\n",
       "     alone  embark_town_Cherbourg  embark_town_Queenstown  \\\n",
       "329      0                    1.0                     0.0   \n",
       "749      1                    0.0                     1.0   \n",
       "203      1                    1.0                     0.0   \n",
       "421      1                    0.0                     1.0   \n",
       "97       0                    1.0                     0.0   \n",
       "..     ...                    ...                     ...   \n",
       "98       0                    0.0                     0.0   \n",
       "322      1                    0.0                     1.0   \n",
       "382      1                    0.0                     0.0   \n",
       "365      1                    0.0                     0.0   \n",
       "510      1                    0.0                     1.0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "329                      0.0  \n",
       "749                      0.0  \n",
       "203                      0.0  \n",
       "421                      0.0  \n",
       "97                       0.0  \n",
       "..                       ...  \n",
       "98                       1.0  \n",
       "322                      0.0  \n",
       "382                      1.0  \n",
       "365                      1.0  \n",
       "510                      0.0  \n",
       "\n",
       "[712 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_test):\n",
    "    \"\"\"Transforms features by scaling each feature to a given range.\n",
    "       Takes in X_train and X_test,\n",
    "       Returns the scaler and X_train_scaled and X_test_scaled within range.\n",
    "       Sensitive to outliers.\n",
    "    \"\"\"\n",
    "    scaler = (sklearn.preprocessing.MinMaxScaler(copy=True, \n",
    "                           feature_range=(0,1))\n",
    "                          .fit(X_train))\n",
    "    X_train_scaled = (pd.DataFrame(scaler.transform(X_train), \n",
    "                      columns=X_train.columns, \n",
    "                      index=X_train.index))\n",
    "    X_test_scaled = (pd.DataFrame(scaler.transform(X_test), \n",
    "                     columns=X_test.columns,\n",
    "                     index=X_test.index))\n",
    "    return scaler, X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['age']]\n",
    "X_test = test[['age']]\n",
    "\n",
    "X_train_scaled, X_test_scaled = min_max_scaler(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_titanic_data()\n",
    "\n",
    "def drop_columns_titanic(df):\n",
    "    df.drop(columns = ['deck', 'embarked', 'class'], inplace = True)\n",
    "    return df\n",
    "\n",
    "def impute_embark_town(train, test):\n",
    "    train.embark_town = train.embark_town.fillna(\"Southampton\")\n",
    "    test.embark_town = test.embark_town.fillna(\"Southampton\")\n",
    "    return train, test\n",
    "\n",
    "def encode_embark_town(train, test):\n",
    "    encoder = sklearn.preprocessing.OneHotEncoder().fit(train[['embark_town']])\n",
    "    \n",
    "    cols = ['embark_town_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "    m = encoder.transform(train[['embark_town']]).todense()\n",
    "    train = pd.concat([\n",
    "        train,\n",
    "        pd.DataFrame(m, columns=cols, index=train.index)\n",
    "    ], axis=1).drop(columns='embark_town')\n",
    "    \n",
    "    m = encoder.transform(test[['embark_town']]).todense()\n",
    "    test = pd.concat([\n",
    "        test,\n",
    "        pd.DataFrame(m, columns=cols, index=test.index)\n",
    "    ], axis=1).drop(columns='embark_town')\n",
    "    return encoder, train, test\n",
    "\n",
    "def impute_age(train, test):\n",
    "    imputer = sklearn.impute.SimpleImputer(strategy='mean')\n",
    "    imputer.fit(train[['age']])\n",
    "    train.age = imputer.transform(train[['age']])\n",
    "    test.age = imputer.transform(test[['age']])\n",
    "    return train, test\n",
    "\n",
    "def scale_columns(train, test):\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    train[['age','fare']] = scaler.fit_transform(train[['age','fare']])\n",
    "    test[['age','fare']] = scaler.transform(test[['age','fare']])\n",
    "    return scaler, train, test\n",
    "\n",
    "def prep_titanic(df):\n",
    "    df = drop_columns_titanic(df)\n",
    "    train, test = sklearn.model_selection.train_test_split(df, random_state=123, train_size=.8)\n",
    "    train, test = impute_embark_town(train, test)\n",
    "    encoder, train, test = encode_embark_town(train, test)\n",
    "    train, test = impute_age(train, test)\n",
    "    scaler, train, test = scale_columns(train, test)\n",
    "    return scaler, encoder, train, test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "scaler, encoder, train, test = prep_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 329 to 510\n",
      "Data columns (total 12 columns):\n",
      "passenger_id               712 non-null int64\n",
      "survived                   712 non-null int64\n",
      "pclass                     712 non-null int64\n",
      "sex                        712 non-null object\n",
      "age                        712 non-null float64\n",
      "sibsp                      712 non-null int64\n",
      "parch                      712 non-null int64\n",
      "fare                       712 non-null float64\n",
      "alone                      712 non-null int64\n",
      "embark_town_Cherbourg      712 non-null float64\n",
      "embark_town_Queenstown     712 non-null float64\n",
      "embark_town_Southampton    712 non-null float64\n",
      "dtypes: float64(5), int64(6), object(1)\n",
      "memory usage: 72.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
